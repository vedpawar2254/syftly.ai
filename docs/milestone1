# Milestone 1: Topic-Based News Ingestion and Situation Feed (India Focus)

## Overview
This milestone establishes the foundational flow for syftly.ai using LangGraph for agent orchestration. Users type in a topic, and the system coordinates two main agents: a Scraper that fetches articles from Indian news sources, and an LLM Agent that intelligently matches topics and synthesizes a unified summary. The goal is to validate LangGraph's workflow orchestration while delivering AI-powered news synthesis from the Indian news ecosystem.

## Architecture Simplification

**Why 2 Agents Instead of 5?**

| Aspect | Multi-Agent Approach (5 agents) | Simplified Approach (2 agents) |
|--------|--------------------------------|--------------------------------|
| **Agents** | Scraper → Preprocessor → Topic Matcher → Synthesizer → Quality Checker | Scraper → LLM Agent |
| **LLM Calls** | 3+ calls per request | 1 call per request |
| **Implementation Time** | 2-3 weeks | ~1 week |
| **Cost per Request** | Higher (multiple LLM calls) | Lower (single LLM call) |
| **Complexity** | State management across 5 agents | Simple linear flow |
| **Maintainability** | Higher complexity | Easier to debug and iterate |

**What Was Combined:**

- **Preprocessor + Scraper**: Simple HTML cleaning done by scraper
- **Topic Matcher + Synthesizer**: LLM handles both filtering and synthesis in one prompt
- **Quality Checker**: Deferred to future milestone (build core flow first)

**Benefits of Simplification:**

1. ✅ Faster to build and validate core LangGraph pattern
2. ✅ Lower LLM API costs (single call vs multiple)
3. ✅ Easier to debug when issues arise
4. ✅ Still demonstrates AI-powered abstractive synthesis
5. ✅ Easy to add more agents later as needs grow

## Flow
1. **User types in a topic** (e.g., "Indian elections", "ISRO launches").
2. **LangGraph orchestrates simple workflow**:
   - **Scraper Agent**: Fetches articles from Indian news sources (The Hindu, Times of India, Indian Express)
   - **LLM Agent**: Performs topic matching, filters relevant articles, and synthesizes them into ONE abstractive summary with source attribution
3. **Situation Feed**: The AI-synthesized summary and supporting articles are displayed in a user-facing feed.
4. **Follow Topic**: Users can choose to follow a topic for future updates.

## Goals
- Demonstrate LangGraph workflow orchestration from topic input to AI-synthesized news feed.
- Validate simple 2-agent architecture: scraping → LLM synthesis.
- Showcase LLM-based abstractive summarization across multiple Indian news sources.
- Build foundation for more complex multi-agent workflows in future milestones.

## Objectives
- **LangGraph Implementation**: Build a LangGraph workflow with 2 agents (Scraper + LLM).
- **Topic-Based Ingestion**: Enable user-driven topic search with LLM-powered article discovery from Indian sources.
- **LLM-Based Synthesis**: Use an LLM agent to synthesize multiple articles into ONE coherent summary with source attribution.
- **Situation Feed**: Display the AI-synthesized summary with supporting articles.
- **Follow Feature**: Allow users to follow topics (store for periodic re-synthesis).
- **Documentation**: Update this file with milestone details and daily progress.

## Scope and Limitations
- **In Scope**:
  - LangGraph workflow with 2 agents (Scraper + LLM)
  - LLM-based topic matching and abstractive synthesis
  - Ingestion from 2-3 major Indian news sources (The Hindu, Times of India, Indian Express)
  - Source attribution in synthesized summaries
  - Minimal UI for feed and follow
- **Out of Scope**:
  - User authentication and notifications
  - Multi-language support (beyond English)
  - Human-in-the-loop feedback integration
  - Quality checking/pipeline validation
  - Mobile support
  - Production-grade error handling and monitoring
- **Constraints**:
  - Use LangGraph for workflow orchestration
  - Keep LLM prompts simple and focused
  - Rate limit LLM API calls to control costs

## Pre-Milestone Validation Tasks
Before implementation begins, complete these validation steps:

1. **LLM API Setup** (CRITICAL)
    - Set up OpenAI or Anthropic API credentials
    - Test basic LLM call for summarization
    - Estimate token costs per request

2. **LangGraph Environment Setup**
    - Install and configure LangGraph dependencies
    - Test a simple 2-agent workflow

3. **Source RSS Verification** (CRITICAL)
    - Test RSS feed URLs for The Hindu, Times of India, Indian Express
    - Document findings in `backend/config/sources.md`

## Technical Implementation

### LangGraph Architecture

**Simple 2-Agent Workflow:**
```mermaid
graph LR
    A[User Topic] --> B[Scraper Agent]
    B --> C[LLM Agent]
    C --> D[Summary + Articles]
```

**State Schema:**
```typescript
interface WorkflowState {
  topic: string;
  articles: Article[];
  summary: string;
  sources: string[];
}
```

### Backend Tasks

1. **LangGraph Setup**:
    - Install dependencies: `npm install @langchain/langgraph @langchain/openai langchain`
    - Create `/backend/graph/newsGraph.js` to define the 2-agent workflow
    - Configure LLM provider (OpenAI GPT-4 or Claude)
    - Define simple state schema

2. **Agent Implementation**:

    a. **Scraper Agent** (`/backend/agents/scraperAgent.js`):
       - Fetches articles from Indian news sources via RSS
       - Returns raw article data: { title, body, source, url, publishDate }
       - **Source Configuration**: `/backend/config/sources.js`:
         ```js
         module.exports = [
           { name: 'The Hindu', type: 'rss', url: 'https://www.thehindu.com/news/national/?service=rss' },
           { name: 'Times of India', type: 'rss', url: 'https://timesofindia.indiatimes.com/rssfeeds/296589292.cms' },
           { name: 'Indian Express', type: 'rss', url: 'https://indianexpress.com/section/india/feed/' }
         ];
         ```

    b. **LLM Agent** (`/backend/agents/llmAgent.js`):
       - Takes articles and topic as input
       - Matches articles to topic semantically
       - Synthesizes into ONE abstractive summary (200-300 words)
       - Includes source attribution throughout
       - **LLM Prompt**:
         ```
         Given the topic "{topic}", review these articles and:
         1. Filter out irrelevant articles
         2. Synthesize the relevant articles into ONE coherent summary (200-300 words)
         3. Include source attribution for key points (e.g., "According to The Hindu...")
         4. Highlight main events and any differing perspectives

         Articles: {articles}

         Return as JSON: { summary, sourcesUsed, matchedArticleIds }
         ```

3. **Situation Feed API**:
     - Add `/backend/routes/feed.js` endpoint: GET `/api/feed?topic=...` triggers LangGraph workflow
     - Add POST `/api/follow` to store followed topics

4. **Database Schema**:
     - `Evidence` collection: { title, body, source, url, publishDate, fetchedAt, topic }
     - `Summary` collection: { topic, summaryText, sourcesUsed, articleIds[], createdAt }
     - `FollowedTopic` collection: { topic, sessionId, createdAt }

### Frontend Tasks
1. **Topic Search UI**:
    - Add input field for users to type a topic (e.g., `/frontend/src/pages/Feed.jsx`).
    - Add submit button to trigger LangGraph workflow.
    - Show loading state while agents are working.

2. **Feed Display**:
    - Show ONE AI-synthesized summary with:
      - Topic title
      - Summary text (200-300 words)
      - Source attribution throughout
      - Source count (e.g., "From 4 sources")
    - Display supporting articles below in a list with:
      - Source name
      - Article title (linked to original URL)
      - Publish date/time
    - Allow users to expand/collapse the article list.

3. **Follow Button**:
    - Add a "Follow [Topic]" button that toggles to "Following".
    - Persist followed topics in localStorage.

4. **Navigation**:
    - Update routing to include `/feed` (main feed page).

### Infrastructure and Testing
- **Database**: MongoDB for storing Evidence, Summaries, and FollowedTopics.
- **LLM Provider**: OpenAI GPT-4 or Claude (configure via environment variable)
- **Dependencies**:
  - Backend: `@langchain/langgraph`, `@langchain/openai`, `langchain`, `rss-parser`, `mongoose`
  - Frontend: React, Axios
- **Testing**:
  - Manual end-to-end test of the workflow
  - Test edge cases: zero articles, single article
- **Environment**: Use dev configs; manage LLM API keys securely.

## Deliverables
- Working LangGraph workflow with 2 agents (Scraper + LLM).
- Feed page displaying AI-synthesized summaries with source attribution.
- Follow feature for topics.
- Ingestion from at least 2 Indian news sources.
- AI-generated abstractive summaries (200-300 words).
- Updated docs/milestone1 with this content.
- Commit message: "feat: Implement Milestone 1 - LangGraph-Based News Synthesis (India Focus)"

## Success Criteria
- User can enter a topic and see ONE AI-synthesized summary with source attribution.
- LangGraph workflow executes both agents without errors.
- Synthesized summary is abstractive and reads naturally.
- Summary includes content from at least 2 different sources.
- User can follow a topic for future updates.
- End-to-end flow completes within 15-20 seconds.
- Common topics return 5+ articles for synthesis.

## Next Steps (Post-Milestone)
- Expand to more sources and languages.
- Add a Quality Checker agent for validation.
- Implement conversational UI for follow-up questions.
- Add notifications and user profiles.
- Expand agent workflow with more specialized agents.

## Rationale
This milestone delivers a tangible, India-focused demo of syftly.ai's core value: surfacing and AI-synthesizing news situations by topic. By using LangGraph:

1. **Establishes a workflow foundation** that can scale to more complex agent architectures
2. **Demonstrates intelligent LLM-based synthesis** (not just keywords or extractive methods)
3. **Creates abstractive summaries** with source attribution that read naturally
4. **Validates the LangGraph pattern** for future expansion (more agents, human-in-the-loop, etc.)

This milestone proves the concept with a simple 2-agent workflow while keeping scope manageable.

## Assumptions
- Selected news sources provide public RSS feeds.
- User topics will be keywords or short phrases.
- LLM API is accessible for development.
- Minimum of 2 articles per topic needed for meaningful synthesis.

## Edge Cases
- **Zero articles found**: Display "No articles found for [topic]. Try a different keyword."
- **Single article found**: Display the article directly instead of AI summary.
- **Source timeout/unavailable**: Skip failed source, proceed with others.
- **LLM API failure**: Display error message and ask user to try again.

## Quality Metrics
- At least 2 news sources successfully ingested.
- Common topics (e.g., "elections", "cricket") return 5+ articles.
- AI-synthesized summary length: 200-300 words.
- End-to-end flow: under 20 seconds.
- Summary includes content from at least 2 different sources.

## Daily Progress Log

### January 24, 2026 - Status: Completed
**Work Completed:**
- Task 1: Pre-Milestone Validation Setup - Installed LangGraph dependencies, verified 3 RSS feeds (The Hindu, Times of India, Indian Express), documented findings
- Task 2: Backend - LangGraph Infrastructure - Created 2-agent workflow with StateAnnotation
- Task 3: Backend - Scraper Agent - Implemented RSS fetching with timeout protection, error handling for failed sources
- Task 4: Backend - LLM Agent - Implemented semantic topic matching and abstractive synthesis with source attribution
- Task 5: Backend - Situation Feed API - Created feed endpoints (GET /topic, POST/DELETE /follow, GET /followed)
- Task 6: Backend - Database Schema - Created TopicSummary and FollowedTopic models with proper indexing
- Task 7-10: Frontend Implementation - Created Feed page with topic search, summary display, articles list, follow button, and navigation
- Task 11: Integration Testing - All tests passed (RSS fetching, LangGraph structure, database connection, edge cases)

**Challenges/Blockers:**
- rss-parser doesn't support AbortSignal - fixed with Promise.race for timeout
- LangGraph StateAnnotation syntax differences - updated to correct format
- LLM API key required for end-to-end testing (user action needed)

**Learnings:**
- RSS feeds are reliable and return consistent data (100-200 articles per source)
- LangGraph workflow can be structured with simple 2-agent architecture
- MongoDB integration works smoothly with existing Evidence model structure

**Next Steps:**
- User to add OPENAI_API_KEY to backend/.env
- Full end-to-end testing with actual LLM synthesis
- Performance validation (target: <20 seconds per request)